{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from math import floor\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "strategies = ['None', 'Specific', 'Generic']\n",
    "temperatures = ['0.0', '0.7']\n",
    "variations = ['0', '1', '2']\n",
    "recursions = ['0', '1']\n",
    "\n",
    "# Pattern for extracting features\n",
    "regex_patterns = {\n",
    "    'Powderkg': r'Powderkg = (\\d+)',\n",
    "    'wc': r'wc = ([\\d.]+)',\n",
    "    'materials': r'materials = ([\\d./]+)',\n",
    "    'curing': r'curing = (.+?)(?:\\n|$)'\n",
    "}\n",
    "\n",
    "def extract_data_for_given_run(pattern):\n",
    "    \"\"\"\n",
    "    :param pattern: Pattern of filenames holding results of experimental runs\n",
    "    :return: Dataframe with all results for the given filename pattern\n",
    "    \"\"\"\n",
    "    matching_filenames = []\n",
    "    # Iterate through the files in the directory\n",
    "    dir_name = 'Results/ID'\n",
    "    for filename in os.listdir(dir_name):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            matching_filenames.append(os.path.join(dir_name, filename))\n",
    "    all_results_df = pd.DataFrame()\n",
    "    warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "    for i, filename in enumerate(matching_filenames):\n",
    "        results_sample_df = pd.read_csv(filename)\n",
    "        for col, pattern in regex_patterns.items():\n",
    "            all_results_df[f'{col} {i}'] = results_sample_df['Formulation'].str.extract(pattern, expand=False)\n",
    "            if col.startswith('materials'):\n",
    "                all_results_df[f'{col} {i}'] = all_results_df[f'{col} {i}'].str[:3]\n",
    "            if col.startswith('curing'):\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Ambient')] = 1\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('ambient')] = 1\n",
    "            all_results_df[f'{col} {i}'] = all_results_df[f'{col} {i}'].astype(float)\n",
    "    return all_results_df, matching_filenames\n",
    "\n",
    "pattern = fr'gpt-3.5-turbo_None 0_prompt_experiment_(\\d+)_temp_0.0_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_0_(\\d+)\\.csv'\n",
    "extract_data_for_given_run(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_combinations = list(product(strategies, temperatures, recursions))\n",
    "\n",
    "def compute_std_over_different_runs(df, number_of_iterations=10):\n",
    "    df = df.copy()\n",
    "    std_for_each_run = []\n",
    "    for i in range(number_of_iterations):\n",
    "        df[i] = df[i].fillna(df[i].mean())\n",
    "        max = df[i].max()\n",
    "        min = df[i].min()\n",
    "        if max - min == 0:\n",
    "            std = df[i].std()\n",
    "        else:\n",
    "            std = df[i].std() / (max - min)\n",
    "        std_for_each_run.append(std)\n",
    "    return np.array(std_for_each_run)\n",
    "\n",
    "\n",
    "def normalize_feature(feature):\n",
    "    max = feature.max()\n",
    "    if max == 0:\n",
    "        max = 1\n",
    "    return feature / max\n",
    "\n",
    "\n",
    "def get_max(df):\n",
    "    max = np.max(df)\n",
    "    if max == 0:\n",
    "        max = 1\n",
    "    return max\n",
    "\n",
    "\n",
    "# DEPRECATED -> keep for comparison (in the functions below we use a simpler way of estimating the std)\n",
    "def compute_overall_std(df_1, df_2, df_3, df_4, number_of_iterations=10):\n",
    "    \"\"\"\n",
    "    :param df_1: powders df\n",
    "    :param df_2: wc df\n",
    "    :param df_3: materials df\n",
    "    :param df_4: curing df\n",
    "    :param number_of_iterations: the number of iterations when running a specific experiment\n",
    "    :return: an approximation for an std at the recipe level (alternative computations might be insightful as well)\n",
    "    \"\"\"\n",
    "    df_1 = df_1.copy()\n",
    "    df_2 = df_2.copy()\n",
    "    df_3 = df_3.copy()\n",
    "    df_4 = df_4.copy()\n",
    "\n",
    "    std_for_each_run = []\n",
    "    recipe_vectors_for_each_run = []\n",
    "\n",
    "    for i in range(number_of_iterations):\n",
    "        df_1[i] = df_1[i].fillna(df_1[i].mean())\n",
    "        df_2[i] = df_2[i].fillna(df_2[i].mean())\n",
    "        df_3[i] = df_3[i].fillna(df_3[i].mean())\n",
    "        df_4[i] = df_4[i].fillna(df_4[i].mean())\n",
    "\n",
    "        df_1[i] = normalize_feature(df_1[i])\n",
    "        square_1 = np.square(df_1[i].values)\n",
    "\n",
    "        df_2[i] = normalize_feature(df_2)\n",
    "        square_2 = np.square(df_2[i].values)\n",
    "\n",
    "        df_3[i] = normalize_feature(df_3[i])\n",
    "        square_3 = np.square(df_3[i].values)\n",
    "\n",
    "        df_4[i] = normalize_feature(df_4[i])\n",
    "        square_4 = np.square(df_4[i].values)\n",
    "\n",
    "        overall_std = np.sqrt(np.std(square_1) + np.std(square_2) + np.std(square_3) + np.std(square_4))\n",
    "        euclidean_recipe_value = np.sqrt(np.mean(square_1) + np.mean(square_2) + np.mean(square_3) + np.mean(square_4))\n",
    "        std_for_each_run.append(overall_std)\n",
    "        recipe_vectors_for_each_run.append(euclidean_recipe_value)\n",
    "\n",
    "    return recipe_vectors_for_each_run, std_for_each_run\n",
    "\n",
    "\n",
    "def find_matching_files(pattern_0, pattern_1,pattern_2):\n",
    "    filenames = []\n",
    "\n",
    "    dir_name = 'Results/ID'\n",
    "    for filename in os.listdir(dir_name):\n",
    "        match = re.match(pattern_0, filename) or re.match(pattern_1, filename) or re.match(pattern_2, filename)\n",
    "        if match:\n",
    "            filenames.append(os.path.join(dir_name, filename))\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def extract_data_for_given_run_for_all_variations(pattern_0, pattern_1, pattern_2):\n",
    "    all_filenames = find_matching_files(pattern_0, pattern_1, pattern_2)\n",
    "\n",
    "    all_runs_df = pd.DataFrame()\n",
    "    warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "    for i, filename in enumerate(all_filenames):\n",
    "        results_sample_df = pd.read_csv(filename)\n",
    "\n",
    "        for col, pattern in regex_patterns.items():\n",
    "            all_runs_df[f'{col} {i}'] = results_sample_df['Formulation'].str.extract(pattern, flags=re.DOTALL,\n",
    "                                                                                     expand=False)\n",
    "            if col.startswith('materials'):\n",
    "                all_runs_df[f'{col} {i}'] = all_runs_df[f'{col} {i}'].str[:3]\n",
    "            if col.startswith('curing'):\n",
    "                all_runs_df[f'{col} {i}'][all_runs_df[f'{col} {i}'].astype(str).str.startswith('Heat')] = 0\n",
    "                all_runs_df[f'{col} {i}'][all_runs_df[f'{col} {i}'].astype(str).str.startswith('heat')] = 0\n",
    "                all_runs_df[f'{col} {i}'][all_runs_df[f'{col} {i}'].astype(str).str.startswith('Ambient')] = 1\n",
    "                all_runs_df[f'{col} {i}'][all_runs_df[f'{col} {i}'].astype(str).str.startswith('ambient')] = 1\n",
    "\n",
    "    return all_runs_df, all_filenames\n",
    "\n",
    "\n",
    "def count_unique_tsne_points(tsne_result):\n",
    "    precision = 2  # Adjust this based on your data and desired precision\n",
    "    rounded_coordinates = np.round(tsne_result, precision)\n",
    "\n",
    "    coordinate_tuples = [tuple(coord) for coord in rounded_coordinates]\n",
    "\n",
    "    unique = {coord: coordinate_tuples.count(coord) for coord in set(coordinate_tuples)}\n",
    "\n",
    "    return len(unique.items())\n",
    "\n",
    "\n",
    "def compute_avg_dist(result, threshold_result):\n",
    "    distances = []\n",
    "    for vector in result:\n",
    "        distances.append(np.linalg.norm(vector - threshold_result))\n",
    "    return np.round(np.mean(distances), 2)\n",
    "\n",
    "\n",
    "def compute_perc_distance(result, threshold_result, perc, top_3=None):\n",
    "    distances = []\n",
    "    found_top_recipe = 0\n",
    "    for vector in result:\n",
    "        if top_3 is not None:\n",
    "            for idx, row  in top_3.iterrows():\n",
    "                if np.array_equal(vector, row.values):\n",
    "                    found_top_recipe = 1\n",
    "        distances.append(np.linalg.norm(vector - threshold_result))\n",
    "    percentile = np.percentile(np.round(distances, 2), perc)\n",
    "    return percentile, found_top_recipe\n",
    "\n",
    "\n",
    "def compute_avg_grad(vector):\n",
    "    diffs = np.array([])\n",
    "    for i in range(len(vector)):\n",
    "        if i < len(vector) - 1:\n",
    "            grad = vector[i + 1] - vector[i]\n",
    "            diffs = np.append(diffs, grad)\n",
    "    return np.round(np.mean(diffs), 2)\n",
    "\n",
    "\n",
    "def get_material_dfs_from_all_results_df():\n",
    "    features = ['Powderkg', 'wc', 'materials', 'curing']\n",
    "    powders = {}\n",
    "    wc_ratios = {}\n",
    "    materials = {}\n",
    "    curing = {}\n",
    "\n",
    "    for feature in features:\n",
    "        for i in range(len(matching_filenames)):\n",
    "            if feature == 'Powderkg':\n",
    "                powders[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].astype(float).values)\n",
    "            elif feature == 'wc':\n",
    "                wc_ratios[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].astype(float).values)\n",
    "            elif feature == 'materials':\n",
    "                materials[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].astype(float).values)\n",
    "            elif feature == 'curing':\n",
    "                curing[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].astype(float).values)\n",
    "\n",
    "    return pd.DataFrame(powders).T, pd.DataFrame(wc_ratios).T, pd.DataFrame(materials).T, pd.DataFrame(curing).T\n",
    "\n",
    "\n",
    "def add_current_iteration_results_to_recipe_vectors(recipes_df, materials_df, iter):\n",
    "    powders = materials_df.feature_dfs[0]\n",
    "    wc = materials_df.feature_dfs[1]\n",
    "    materials = materials_df.feature_dfs[2]\n",
    "    curing = materials_df.feature_dfs[3]\n",
    "\n",
    "    powders[iter] = powders[iter].fillna(powders[iter].mean())\n",
    "    wc[iter] = wc[iter].fillna(wc[iter].mean())\n",
    "    materials[iter] = materials[iter].fillna(materials[iter].mean())\n",
    "    curing[iter] = curing[iter].fillna(curing[iter].mean())\n",
    "\n",
    "    iter_df = pd.DataFrame(\n",
    "        {\n",
    "            'powders': powders[iter].values / materials_df.max_values[0],\n",
    "            'wc': wc[iter].values / materials_df.max_values[1],\n",
    "            'materials': materials[iter].values / materials_df.max_values[2],\n",
    "            'curing': curing[iter].values / materials_df.max_values[3]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pd.concat([recipes_df, iter_df])\n",
    "\n",
    "\n",
    "def create_recipe_vectors(materials_df):\n",
    "    recipes = pd.DataFrame(columns=[])\n",
    "    # All materials df have the shape 1 -> we can use any in the range function\n",
    "    nr_iter = df_powders.shape[1]\n",
    "    for iteration in range(nr_iter):\n",
    "        recipes = add_current_iteration_results_to_recipe_vectors(recipes, materials_df, iteration)\n",
    "    return recipes\n",
    "\n",
    "\n",
    "def find_top_recipes(max_values, with_threshold=True):\n",
    "    # threshold from Inverse Design Results.ipynb\n",
    "    threshold = 64.86370000000001\n",
    "    top = pd.read_csv('Data/Top4.csv',\n",
    "                      usecols=['powders', 'wc', 'materials', 'curing', 'fc_28d'],\n",
    "                      dtype={\n",
    "                          'powders': float,\n",
    "                          'wc': float,\n",
    "                          'materials': float,\n",
    "                          'curing': float,\n",
    "                          'fc_28d': float\n",
    "                      })\n",
    "    if with_threshold:\n",
    "        top = top[top['fc_28d'] > threshold]\n",
    "    top = top[['powders', 'wc', 'materials', 'curing']]\n",
    "    top['powders'] = top['powders'] / max_values[0]\n",
    "    top['wc'] = top['wc'] / max_values[1]\n",
    "    top['materials'] = top['materials'] / max_values[2]\n",
    "    top['curing'] = top['curing'] / max_values[3]\n",
    "\n",
    "    return top\n",
    "\n",
    "\n",
    "def plot_recipes_in_2d(tsne_data, original_recipes, threshold_recipe, nr_of_top_recipes, top_3, model):\n",
    "    nr_of_runs_per_conf = df_powders.shape[0]\n",
    "    top_tsne_result = tsne_data[len(tsne_data) - nr_of_top_recipes:len(tsne_data)]\n",
    "\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "    color_idx = 0\n",
    "    avg_distances = []\n",
    "    min_distances = []\n",
    "    min_distances_0 = []\n",
    "    max_distances = []\n",
    "    max_distances_100 = []\n",
    "\n",
    "    found_top_recipe_list = []\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(0, len(tsne_data) - nr_of_top_recipes, nr_of_runs_per_conf):\n",
    "        subset_tsne_result = tsne_data[i:i + nr_of_runs_per_conf]\n",
    "\n",
    "\n",
    "        # Count occurrences of each unique combination of t-SNE coordinates\n",
    "        tmp = pd.DataFrame(subset_tsne_result)\n",
    "        occurrences = tmp.round(decimals=2).value_counts().values\n",
    "\n",
    "        unique_count = count_unique_tsne_points(subset_tsne_result)\n",
    "\n",
    "        subset_original_recipes = original_recipes[i:i + nr_of_runs_per_conf].values\n",
    "        avg_dist = compute_avg_dist(subset_original_recipes, threshold_recipe.values)\n",
    "        min_distance, found_top_recipe = compute_perc_distance(subset_original_recipes, threshold_recipe.values, 10, top_3)\n",
    "        min_distance_0, found_top_recipe = compute_perc_distance(subset_original_recipes, threshold_recipe.values, 0, top_3)\n",
    "        max_distance, _ = compute_perc_distance(subset_original_recipes, threshold_recipe.values, 90)\n",
    "        max_distance_100, _ = compute_perc_distance(subset_original_recipes, threshold_recipe.values, 100)\n",
    "\n",
    "        avg_distances.append(avg_dist)\n",
    "        min_distances.append(min_distance)\n",
    "        min_distances_0.append(min_distance_0)\n",
    "        max_distances.append(max_distance)\n",
    "        max_distances_100.append(max_distance_100)\n",
    "        found_top_recipe_list.append(found_top_recipe)\n",
    "\n",
    "        tmp = tmp.drop_duplicates()\n",
    "        subset_tsne_result = tmp.values\n",
    "        for row in range(subset_tsne_result.shape[0]):\n",
    "            if row == subset_tsne_result.shape[0] - 1:\n",
    "                plt.scatter(subset_tsne_result[row, 0], subset_tsne_result[row, 1],\n",
    "                            s=occurrences[row] * 15,\n",
    "                            color=colors[color_idx],\n",
    "                            label=f'Iteration {i // nr_of_runs_per_conf + 1} ({unique_count}, {avg_dist}, {min_distance})')\n",
    "            else:\n",
    "                plt.scatter(subset_tsne_result[row, 0], subset_tsne_result[row, 1],\n",
    "                            s=occurrences[row] * 20,\n",
    "                            color=colors[color_idx],\n",
    "                            label=None)\n",
    "        color_idx += 1\n",
    "\n",
    "    avg_distances = set_dist_to_best_so_far(avg_distances)\n",
    "    min_distances = set_dist_to_best_so_far(min_distances)\n",
    "    min_distances_0 = set_dist_to_best_so_far(min_distances_0)\n",
    "    max_distances = set_dist_to_best_so_far(max_distances)\n",
    "    max_distances_100 = set_dist_to_best_so_far(max_distances_100)\n",
    "\n",
    "    plt.scatter(top_tsne_result[0, 0], top_tsne_result[0, 1], marker='x', color='red', s=120)\n",
    "    plt.scatter(top_tsne_result[1:, 0], top_tsne_result[1:, 1], marker='x', color='red', s=30,\n",
    "                label=f'Top Recipes')\n",
    "\n",
    "    plt.xlabel('TSNE - x')\n",
    "    plt.ylabel('TSNE - y')\n",
    "\n",
    "    max_x = np.max(np.abs(tsne_data)[:, 0])\n",
    "    max_y = np.max(np.abs(tsne_data)[:, 1])\n",
    "\n",
    "    x_axis = list(range(- floor(max_x) - 50, floor(max_x) + 50))\n",
    "    x_axis = [tick for tick in x_axis if tick % 100 == 0]\n",
    "    y_axis = list(range(- floor(max_y) - 50, floor(max_y) + 50))\n",
    "    y_axis = [tick for tick in y_axis if tick % 100 == 0]\n",
    "    plt.xticks(x_axis, rotation=45)\n",
    "    plt.yticks(y_axis)\n",
    "    lgd =plt.legend(loc='upper left', bbox_to_anchor=(1, 1), handlelength=2, handleheight=2)\n",
    "    for handle in lgd.legend_handles:\n",
    "        handle.set_sizes([30.0])\n",
    "    # plt.text(0, - max_y - 0.4 * max_y, 'TSNE visualisation of recipes proposed by the LLM. The dots show the proposed recipes.\\n'\n",
    "    #          'Their size indicated how ofter GPT selected a recipe at a given iteration.\\n'\n",
    "    #          'The crosses show the 4 recipes corresponding to the highest compressive strengths.\\n'\n",
    "    #          'The numbers in the legend indicate the following: count of distinct recipes proposed at the iteration,\\n'\n",
    "    #          'average distance of the proposed recipe to the best recipe, distance of proposed recipe closest to the\\n'\n",
    "    #          'best recipe at the given iteration.', ha='center', fontsize=12)\n",
    "    plt.title(f'TSNE along with unique recipes and their avg distance ({strategy} {temperature} {recursion})')\n",
    "    plt.show()\n",
    "    # plt.savefig(f'Results/Recipe_Distribution_Analysis/TSNE for Strategy {strategy} Temperature {temperature} Recursion {recursion}.png', bbox_inches='tight')\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(np.arange(len(avg_distances)), np.array(avg_distances), label='Average Distance to 99th Percentile', color='blue')\n",
    "\n",
    "    if sum(found_top_recipe_list) > 0:\n",
    "        iter_with_top_recipe_found = found_top_recipe_list.index(1)\n",
    "        # plt.scatter(np.arange(len(avg_distances))[iter_with_top_recipe_found:], np.array(avg_distances)[iter_with_top_recipe_found:], s=100, marker='x', label='Top Prediction', color='red')\n",
    "\n",
    "    plt.fill_between(np.arange(len(avg_distances)), np.array(min_distances), np.array(max_distances),\n",
    "                     color='blue',\n",
    "                     alpha=0.3,\n",
    "                     label='90th and 10th Percentiles in Recipe Space')\n",
    "    plt.fill_between(np.arange(len(avg_distances)), np.array(min_distances_0), np.array(min_distances),\n",
    "                     color='yellow',\n",
    "                     alpha=0.3,\n",
    "                     label='Best and Worst Predictions')\n",
    "    plt.fill_between(np.arange(len(avg_distances)), np.array(max_distances), np.array(max_distances_100),\n",
    "                     color='yellow',\n",
    "                     alpha=0.3)\n",
    "    # plt.axhline(y=0, color='r', linestyle='--', label='99 percentile recipe')\n",
    "\n",
    "    plt.ylim(0, 1.2)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Normalized Distance')\n",
    "\n",
    "    if recursion == '1':\n",
    "        tt = 'Increased TT'\n",
    "    else:\n",
    "        tt = 'Baseline'\n",
    "\n",
    "    plt.title(f'Model: {model}, Information Quality {strategy}, Temperature {temperature}, Strategy {tt}')\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'Results/Recipe_Distribution_Analysis/Recipe_Distances/{model}, {strategy}, {temperature}, {tt}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "def set_dist_to_best_so_far(distances):\n",
    "    for i in range(1, len(distances)):\n",
    "        if distances[i] > distances[i - 1]:\n",
    "            distances[i] = distances[i - 1]\n",
    "    return distances\n",
    "\n",
    "\n",
    "def postion_top_4_relative_to_best(top_recipes, best_recipe_df):\n",
    "    top_recipes['powders'] = top_recipes['powders'] - best_recipe_df['powders']\n",
    "    top_recipes['wc'] = top_recipes['wc'] - best_recipe_df['wc']\n",
    "    top_recipes['materials'] = top_recipes['materials'] - best_recipe_df['materials']\n",
    "    top_recipes['curing'] = top_recipes['curing'] - best_recipe_df['curing']\n",
    "    return top_recipes\n",
    "\n",
    "\n",
    "class MaterialsDataframes:\n",
    "\n",
    "    def __init__(self, feature_dfs, max_values):\n",
    "        self.feature_dfs = feature_dfs\n",
    "        self.max_values = max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "configs_with_less_than_ten_iterations = 0\n",
    "\n",
    "std_statistics = pd.DataFrame({\n",
    "    'configuration': [],\n",
    "    'mean_std': [],\n",
    "    'max_std': [],\n",
    "    'min_std': [],\n",
    "    'avg_std_gradient': [],\n",
    "    'initial_std': [],\n",
    "    'halftime_std': [],\n",
    "    'final_std': []\n",
    "})\n",
    "\n",
    "model='gpt-3.5-turbo'\n",
    "\n",
    "for combination in all_combinations:\n",
    "    strategy = combination[0]\n",
    "    temperature = combination[1]\n",
    "    recursion = combination[2]\n",
    "\n",
    "    if model == 'gpt-4-1106-preview' and recursion == '1':\n",
    "        continue\n",
    "\n",
    "    print(f'####### Run with strategy {strategy}, temperature {temperature} and recursion {recursion} #########')\n",
    "\n",
    "    pattern_0 = fr'{model}_{strategy} 0_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    pattern_1 = fr'{model}_{strategy} 1_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    pattern_2 = fr'{model}_{strategy} 2_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "\n",
    "    all_results_df, matching_filenames = extract_data_for_given_run_for_all_variations(pattern_0, pattern_1, pattern_2)\n",
    "\n",
    "    # TODO: properly handle this case\n",
    "    number_of_iterations = len(all_results_df)\n",
    "    if not matching_filenames or number_of_iterations != 10:\n",
    "        print(f'Warning: Some of the files for {strategy} {temperature} {recursion} have less than 10 rows per dataframe')\n",
    "        print(f'Nr. of iterations: {number_of_iterations}')\n",
    "        configs_with_less_than_ten_iterations = configs_with_less_than_ten_iterations + 1\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "\n",
    "    df_powders, df_wc, df_materials, df_curing = get_material_dfs_from_all_results_df()\n",
    "\n",
    "    max_powders = get_max(df_powders)\n",
    "    max_wc = get_max(df_wc)\n",
    "    max_materials = get_max(df_materials)\n",
    "    max_curing = get_max(df_curing)\n",
    "\n",
    "    materials_df = MaterialsDataframes(feature_dfs=[df_powders, df_wc, df_materials, df_curing],\n",
    "                                       max_values=[max_powders, max_wc, max_materials, max_curing])\n",
    "\n",
    "    top_recipes = find_top_recipes(materials_df.max_values)\n",
    "    df_recipe_vectors = create_recipe_vectors(materials_df)\n",
    "\n",
    "    df_recipe_vectors = pd.concat([df_recipe_vectors, top_recipes])\n",
    "    df_recipe_vectors = df_recipe_vectors.dropna(axis=1)\n",
    "\n",
    "    tsne_result = TSNE(n_components=2, perplexity=20, learning_rate=200, early_exaggeration=12, random_state=42, n_iter=1000).fit_transform(df_recipe_vectors.values)\n",
    "    # normiere, so dass das beste Rezept im Zentrum dargestellt wird\n",
    "    tsne_result = tsne_result - tsne_result[-len(top_recipes)]\n",
    "\n",
    "    plot_recipes_in_2d(tsne_result, df_recipe_vectors, top_recipes.iloc[len(top_recipes) - 1], len(top_recipes), top_recipes, model)\n",
    "\n",
    "    ####### Standard Deviations #######\n",
    "    std_for_each_run_powder = compute_std_over_different_runs(df_powders, number_of_iterations)\n",
    "    std_for_each_run_wc = compute_std_over_different_runs(df_wc, number_of_iterations)\n",
    "    std_for_each_run_materials = compute_std_over_different_runs(df_materials, number_of_iterations)\n",
    "    std_for_each_run_curing = compute_std_over_different_runs(df_curing, number_of_iterations)\n",
    "\n",
    "    std_for_statistics = std_for_each_run_powder + std_for_each_run_wc + std_for_each_run_materials + std_for_each_run_curing\n",
    "\n",
    "    std_statistics.loc[len(std_statistics)] = {\n",
    "        'configuration': f'{strategy} {temperature} {recursion}',\n",
    "        'mean_std': np.mean(std_for_statistics),\n",
    "        'max_std': np.max(std_for_statistics),\n",
    "        'min_std': np.min(std_for_statistics),\n",
    "        'avg_std_gradient': compute_avg_grad(std_for_statistics),\n",
    "        'initial_std': std_for_statistics[0],\n",
    "        'halftime_std': std_for_statistics[floor(number_of_iterations / 2)],\n",
    "        'final_std': std_for_statistics[number_of_iterations - 1],\n",
    "    }\n",
    "\n",
    "    nr_iterations = np.arange(0, number_of_iterations)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.plot(nr_iterations, std_for_each_run_powder, label='powderkg')\n",
    "    plt.plot(nr_iterations, std_for_each_run_wc, label='wc')\n",
    "    plt.plot(nr_iterations, std_for_each_run_materials, label='materials')\n",
    "    plt.plot(nr_iterations, std_for_each_run_curing, label='curing')\n",
    "\n",
    "    plt.plot(nr_iterations, std_for_statistics, label='Full Std')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.title(f'Std evolution for {strategy} {temperature} {recursion}')\n",
    "\n",
    "    plt.show()\n",
    "    # plt.savefig(f'Results/Recipe_Distribution_Analysis/Full Std evolution for Strategy {strategy} Temperature {temperature} Recursion {recursion}.png', bbox_inches='tight')\n",
    "\n",
    "std_statistics.to_csv('Results/Recipe_Distribution_Analysis/Full std_statistics.csv')\n",
    "\n",
    "print(f'####### Nr of warnings: {configs_with_less_than_ten_iterations} #######')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}