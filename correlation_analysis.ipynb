{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "strategies = ['None', 'Specific', 'Generic']\n",
    "temperatures = ['0.0', '0.7']\n",
    "variations = ['0', '1', '2']\n",
    "recursions = ['0', '1']\n",
    "\n",
    "regex_patterns = {\n",
    "    'Powderkg': r'Powderkg = (\\d+)',\n",
    "    'wc': r'wc = ([\\d.]+)',\n",
    "    'materials': r'materials = ([\\d./]+)',\n",
    "    'curing': r'curing = (.+?)(?:\\n|$)'\n",
    "}\n",
    "\n",
    "\n",
    "def find_explained_variance_using_pca(correlation_matrix, feature, strategy, temperature):\n",
    "    pca = PCA(n_components=1)\n",
    "    data = pd.DataFrame(correlation_matrix)\n",
    "    pca.fit(data)\n",
    "    # Get the first principal component\n",
    "    first_principal_component = pca.components_[0]\n",
    "    # Print the explained variance ratio, which tells you the proportion of variance\n",
    "    # explained by the first principal component.\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(f\"Explained Variance Ratio for {feature}, {strategy} and {temperature}:\", explained_variance_ratio)\n",
    "    # Print the first principal component, which represents the overall relationship\n",
    "    print(f\"First Principal Component (Overall Relationship) for {feature}, {strategy} and {temperature}:\",\n",
    "          first_principal_component)\n",
    "\n",
    "\n",
    "def perform_correlation_analysis(feature, strategy, temperature, variation, recursion):\n",
    "    correlation_matrix = df.corr()\n",
    "    correlation_matrix = correlation_matrix.apply(lambda x: round(x, 2))\n",
    "    average_cc_per_run = correlation_matrix.mean()\n",
    "    correlation_matrix['Average Correlation'] = average_cc_per_run\n",
    "    print('AVERAGE CORRELATION COEFFICIENT PER RUN')\n",
    "    print(average_cc_per_run)\n",
    "    overall_average_cc = correlation_matrix.stack().mean()\n",
    "    print('OVERALL CORRELATION COEFFICIENT')\n",
    "    print(overall_average_cc)\n",
    "    # NaNs occur when the std is 0, i.e. we have constant functions. We handle this cas by replacing NaN with 1\n",
    "    correlation_matrix.fillna(1, inplace=True)\n",
    "    correlation_matrix.to_csv(\n",
    "        f'Results/Correlation_Analysis/correlation_matrix_{feature}_{strategy}_{variation}_{temperature}_{recursion}.csv')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "    # Customize the plot (add labels, title, etc. if needed)\n",
    "    plt.title(f'Correlation Heatmap {strategy} {temperature}')\n",
    "    plt.show()\n",
    "    # plt.savefig(\n",
    "    #     f'Results/Correlation_Analysis/images/correlation_matrix_{feature}_{strategy}_{variation}_{temperature}_{recursion}.png',\n",
    "    #     bbox_inches='tight')\n",
    "    return correlation_matrix\n",
    "\n",
    "\n",
    "def plot_individual_experiments(feature, strategy, temperature):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(df.index, df[f'{feature} 1'], label=f'{feature} Experiment 1')\n",
    "    plt.plot(df.index, df[f'{feature} 2'], label=f'{feature} Experiment 2')\n",
    "    plt.plot(df.index, df[f'{feature} 3'], label=f'{feature} Experiment 3')\n",
    "    plt.legend()\n",
    "    plt.title(f'Lineplot for {strategy} and {temperature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_data_for_given_run(pattern):\n",
    "    matching_filenames = []\n",
    "    # Iterate through the files in the directory\n",
    "    dir_name = 'Results/ID'\n",
    "    for filename in os.listdir(dir_name):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            matching_filenames.append(os.path.join(dir_name, filename))\n",
    "    all_results_df = pd.DataFrame()\n",
    "    warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "    for i, filename in enumerate(matching_filenames):\n",
    "        results_sample_df = pd.read_csv(filename)\n",
    "        for col, pattern in regex_patterns.items():\n",
    "            all_results_df[f'{col} {i}'] = results_sample_df['Formulation'].str.extract(pattern, expand=False)\n",
    "            if col.startswith('materials'):\n",
    "                all_results_df[f'{col} {i}'] = all_results_df[f'{col} {i}'].str[:3].astype(float)\n",
    "            if col.startswith('curing'):\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Ambient')] = 1\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('ambient')] = 1\n",
    "    return all_results_df, matching_filenames\n",
    "\n",
    "\n",
    "def tsne_for_feature(feature, strategy, temperature):\n",
    "    X_2d = tsne.fit_transform(df_transpose)\n",
    "    # Create a scatter plot of the t-SNE results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c='r', marker='o', label=feature)\n",
    "    plt.title(f\"t-SNE Visualization {strategy} {temperature}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tsne_for_all_features(all_features_for_tsne, strategy, temperature):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_features_for_tsne)\n",
    "    # Transform your DataFrame to apply the scaling\n",
    "    scaled = pd.DataFrame(scaler.transform(all_features_for_tsne))\n",
    "    tsne = TSNE(n_components=2, perplexity=2, random_state=0)\n",
    "    X_2d = tsne.fit_transform(scaled)\n",
    "    # Create a scatter plot of the t-SNE results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c='r', marker='o', label='All Features')\n",
    "    plt.title(f\"t-SNE Visualization all features {strategy} {temperature}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pca_and_corr_on_all_features(df):\n",
    "    correlation_matrix = df.corr()\n",
    "    correlation_matrix = correlation_matrix.apply(lambda x: round(x, 8))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "    # Customize the plot (add labels, title, etc. if needed)\n",
    "    plt.title('Correlation Heatmap between Lineplots')\n",
    "    plt.show()\n",
    "    pca = PCA(n_components=1)\n",
    "    data = pd.DataFrame(correlation_matrix)\n",
    "    pca.fit(data)\n",
    "    # Get the first principal component\n",
    "    first_principal_component = pca.components_[0]\n",
    "    # Print the explained variance ratio, which tells you the proportion of variance\n",
    "    # explained by the first principal component.\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(\"Explained Variance Ratio:\", explained_variance_ratio)\n",
    "    # Print the first principal component, which represents the overall relationship\n",
    "    print(\"First Principal Component (Overall Relationship):\", first_principal_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "all_combinations = list(product(strategies, variations, temperatures, recursions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Correlation Analyses between different runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for combination in all_combinations:\n",
    "    strategy = combination[0]\n",
    "    variation = combination[1]\n",
    "    temperature = combination[2]\n",
    "    recursion = combination[3]\n",
    "    print('#####################################################################################')\n",
    "    print(\n",
    "        f'######### Run with strategy {strategy}, variation {variation}, temperature {temperature} and recursion {recursion} #########')\n",
    "    print('#####################################################################################')\n",
    "    pattern = fr'gpt-3.5-turbo_{strategy} {variation}_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    all_results_df, matching_filenames = extract_data_for_given_run(pattern)\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "\n",
    "    features = ['Powderkg', 'wc', 'materials']\n",
    "    for feature in features:\n",
    "        print(f'################ Feature {feature} ################')\n",
    "        data = {}\n",
    "        for i in range(len(matching_filenames)):\n",
    "            data[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        correlation_matrix = perform_correlation_analysis(feature, strategy, temperature, variation, recursion)\n",
    "        # plot_individual_experiments(feature, strategy, temperature)\n",
    "        find_explained_variance_using_pca(correlation_matrix, feature, strategy, temperature)\n",
    "\n",
    "        tsne = TSNE(n_components=2, perplexity=2, random_state=0)\n",
    "        df_transpose = df.T\n",
    "        if feature == 'Powderkg':\n",
    "            all_features_for_tsne = df_transpose.values\n",
    "        else:\n",
    "            all_features_for_tsne = np.hstack((all_features_for_tsne, df_transpose.values))\n",
    "        # Comment in in case you want to have a tsne visualisation\n",
    "        # tsne_for_feature(feature, strategy, temperature)\n",
    "\n",
    "    # Comment in in case you want to have a tsne visualisation\n",
    "    # tsne_for_all_features(all_features_for_tsne, strategy, temperature)\n",
    "\n",
    "    df = pd.DataFrame(all_features_for_tsne).T\n",
    "    df.head(30)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "\n",
    "    # Transform your DataFrame to apply the scaling\n",
    "    scaled_df = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "\n",
    "    plt.plot(scaled_df.index, scaled_df[1].astype(str))\n",
    "    plt.plot(scaled_df.index, scaled_df[2].astype(str))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # pca_and_corr_on_all_features(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from itertools import product\n",
    "\n",
    "all_combinations = list(product(strategies, temperatures, recursions))\n",
    "\n",
    "\n",
    "def plot_distribution(df):\n",
    "    print(df)\n",
    "    plt.hist(df[0], bins=10, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_std_over_different_runs(df, number_of_iterations=10):\n",
    "    df = df.copy()\n",
    "    std_for_each_run = []\n",
    "    for i in range(number_of_iterations):\n",
    "        df[i] = df[i].fillna(df[i].astype(float).mean())\n",
    "        max = df[i].astype(float).max()\n",
    "        min = df[i].astype(float).min()\n",
    "        if max - min == 0:\n",
    "            std = df[i].astype(float).std()\n",
    "        else:\n",
    "            std = df[i].astype(float).std() / (max - min)\n",
    "        std_for_each_run.append(std)\n",
    "    return np.array(std_for_each_run)\n",
    "\n",
    "\n",
    "def compute_overall_std(df_1, df_2, df_3, df_4, number_of_iterations=10):\n",
    "    df_1 = df_1.copy()\n",
    "    df_2 = df_2.copy()\n",
    "    df_3 = df_3.copy()\n",
    "    df_4 = df_4.copy()\n",
    "\n",
    "    std_for_each_run = []\n",
    "    recipe_vectors_for_each_run = []\n",
    "\n",
    "    for i in range(number_of_iterations):\n",
    "        df_1[i] = df_1[i].fillna(df_1[i].astype(float).mean())\n",
    "        df_2[i] = df_2[i].fillna(df_2[i].astype(float).mean())\n",
    "        df_3[i] = df_3[i].fillna(df_3[i].astype(float).mean())\n",
    "        df_4[i] = df_4[i].fillna(df_4[i].astype(float).mean())\n",
    "\n",
    "        # TODO: CHECK\n",
    "        # data = np.array([df_1[i].astype(float).values,\n",
    "        #                  df_2[i].astype(float).values,\n",
    "        #                  df_3[i].astype(float).values,\n",
    "        #                  df_4[i].astype(float).values])\n",
    "        # sample_variance = np.var(data, axis=0, ddof=1)\n",
    "        # std_for_each_run.append(sample_variance / (15 * np.max(sample_variance)))\n",
    "\n",
    "        max_1 = df_1[i].astype(float).max()\n",
    "        if max_1 == 0:\n",
    "            max_1 = 1\n",
    "        df_1[i] = df_1[i].astype(float) / max_1\n",
    "        square_1 = np.square(df_1[i].values)\n",
    "\n",
    "        max_2 = df_2[i].astype(float).max()\n",
    "        if max_2 == 0:\n",
    "            max_2 = 1\n",
    "        df_2[i] = df_2[i].astype(float) / max_2\n",
    "        square_2 = np.square(df_2[i].values)\n",
    "\n",
    "        max_3 = df_3[i].astype(float).max()\n",
    "        if max_3 == 0:\n",
    "            max_3 = 1\n",
    "        df_3[i] = df_3[i].astype(float) / max_3\n",
    "        square_3 = np.square(df_3[i].values)\n",
    "        max_4 = df_4[i].astype(float).max()\n",
    "        if max_4 == 0:\n",
    "            max_4 = 1\n",
    "        df_4[i] = df_4[i].astype(float) / max_4\n",
    "        square_4 = np.square(df_4[i].values)\n",
    "\n",
    "        overall_std = np.sqrt(np.std(square_1) + np.std(square_2) + np.std(square_3) + np.std(square_4))\n",
    "        euclidean_recipe_value = np.sqrt(np.mean(square_1) + np.mean(square_2) + np.mean(square_3) + np.mean(square_4))\n",
    "        std_for_each_run.append(overall_std)\n",
    "        recipe_vectors_for_each_run.append(euclidean_recipe_value)\n",
    "    return recipe_vectors_for_each_run, std_for_each_run\n",
    "\n",
    "\n",
    "def extract_data_for_given_run_for_all_variations(pattern_0, pattern_1, pattern_2):\n",
    "    matching_filenames = []\n",
    "    # Iterate through the files in the directory\n",
    "    dir_name = 'Results/ID'\n",
    "    for filename in os.listdir(dir_name):\n",
    "        match = re.match(pattern_0, filename) or re.match(pattern_1, filename) or re.match(pattern_2, filename)\n",
    "        if match:\n",
    "            matching_filenames.append(os.path.join(dir_name, filename))\n",
    "    all_results_df = pd.DataFrame()\n",
    "    warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "    for i, filename in enumerate(matching_filenames):\n",
    "        results_sample_df = pd.read_csv(filename)\n",
    "\n",
    "        for col, pattern in regex_patterns.items():\n",
    "            all_results_df[f'{col} {i}'] = results_sample_df['Formulation'].str.extract(pattern, flags=re.DOTALL,\n",
    "                                                                                        expand=False)\n",
    "            if col.startswith('materials'):\n",
    "                all_results_df[f'{col} {i}'] = all_results_df[f'{col} {i}'].str[:3].astype(float)\n",
    "            if col.startswith('curing'):\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Ambient')] = 1\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('ambient')] = 1\n",
    "\n",
    "    return all_results_df, matching_filenames\n",
    "\n",
    "\n",
    "configs_with_less_than_ten_iterations = 0\n",
    "std_statistics = pd.DataFrame({\n",
    "    'configuration': [],\n",
    "    'mean_std': [],\n",
    "    'max_std': [],\n",
    "    'min_std': [],\n",
    "    'avg_std_gradient': [],\n",
    "    'initial_std': [],\n",
    "    'halftime_std': [],\n",
    "    'final_std': []\n",
    "})\n",
    "\n",
    "\n",
    "def _compute_avg_grad(vector):\n",
    "    diffs = np.array([])\n",
    "    for i in range(len(vector)):\n",
    "        if i < len(vector) - 1:\n",
    "            grad = vector[i + 1] - vector[i]\n",
    "            diffs = np.append(diffs, grad)\n",
    "    return np.mean(diffs)\n",
    "\n",
    "def count_unique_tsne_points(tsne_result):\n",
    "    precision = 2  # Adjust this based on your data and desired precision\n",
    "    rounded_coordinates = np.round(tsne_result, precision)\n",
    "\n",
    "    coordinate_tuples = [tuple(coord) for coord in rounded_coordinates]\n",
    "\n",
    "    unique = {coord: coordinate_tuples.count(coord) for coord in set(coordinate_tuples)}\n",
    "\n",
    "    return len(unique.items())\n",
    "\n",
    "def compute_avg_tsne_dist(tsne_result):\n",
    "    pairwise_distances = pdist(tsne_result)\n",
    "\n",
    "    return np.mean(pairwise_distances)\n",
    "\n",
    "# change to display recipe vector instead\n",
    "full = True\n",
    "\n",
    "for combination in all_combinations[:4]:\n",
    "    strategy = combination[0]\n",
    "    temperature = combination[1]\n",
    "    recursion = combination[2]\n",
    "\n",
    "    print('#####################################################################################')\n",
    "    print(f'####### Run with strategy {strategy}, temperature {temperature} and recursion {recursion} #########')\n",
    "    print('#####################################################################################')\n",
    "\n",
    "    pattern_0 = fr'gpt-3.5-turbo_{strategy} 0_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    pattern_1 = fr'gpt-3.5-turbo_{strategy} 1_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    pattern_2 = fr'gpt-3.5-turbo_{strategy} 2_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_{recursion}_(\\d+)\\.csv'\n",
    "    all_results_df, matching_filenames = extract_data_for_given_run_for_all_variations(pattern_0, pattern_1, pattern_2)\n",
    "\n",
    "    # TODO: properly handle this case\n",
    "    number_of_iterations = len(all_results_df)\n",
    "    if not matching_filenames or number_of_iterations != 10:\n",
    "        print(f'Warning: Some of the files for {strategy} {temperature} {recursion} have less than 10 rows per dataframe')\n",
    "        configs_with_less_than_ten_iterations = configs_with_less_than_ten_iterations + 1\n",
    "        if strategy == 'Specific' and temperature == '0.0' and recursion == '0':\n",
    "            print('\\n'.join(matching_filenames))\n",
    "\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "\n",
    "    features = ['Powderkg', 'wc', 'materials', 'curing']\n",
    "    powders = {}\n",
    "    wc_ratios = {}\n",
    "    materials = {}\n",
    "    curing = {}\n",
    "\n",
    "    for feature in features:\n",
    "        for i in range(len(matching_filenames)):\n",
    "            if feature == 'Powderkg':\n",
    "                powders[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "            elif feature == 'wc':\n",
    "                wc_ratios[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "            elif feature == 'materials':\n",
    "                materials[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "            elif feature == 'curing':\n",
    "                curing[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "\n",
    "    # TODO: Check plots which show weird behaviour in detail\n",
    "    df_powders = pd.DataFrame(powders).T\n",
    "    df_wc = pd.DataFrame(wc_ratios).T\n",
    "    df_materials = pd.DataFrame(materials).T\n",
    "    df_curing = pd.DataFrame(curing).T\n",
    "    # plot_distribution(df_powders)\n",
    "    # plot_distribution(df_wc)\n",
    "    # plot_distribution(df_materials)\n",
    "\n",
    "    ####### TSNE #######\n",
    "\n",
    "    # Wir fitten den Scaler auf allen Iterationen so dass wir verschiedene Durchläufe in einem Plot miteinander vergleichen können\n",
    "    # 10 -> number of iterations\n",
    "\n",
    "    max_powders = np.max(df_powders.astype(float))\n",
    "    if max_powders == 0:\n",
    "        max_powders = 1\n",
    "    max_wc = np.max(df_wc.astype(float))\n",
    "    if max_wc == 0:\n",
    "        max_wc = 1\n",
    "    max_materials = np.max(df_materials.astype(float))\n",
    "    if max_materials == 0:\n",
    "        max_materials = 1\n",
    "    max_curing = np.max(df_curing.astype(float))\n",
    "    if max_curing == 0:\n",
    "        max_curing = 1\n",
    "\n",
    "    df_recipe_vectors = pd.DataFrame()\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    for i in range(df_powders.shape[1]):\n",
    "        df_powders[i] = df_powders[i].fillna(df_powders[i].astype(float).mean())\n",
    "        df_wc[i] = df_wc[i].fillna(df_wc[i].astype(float).mean())\n",
    "        df_materials[i] = df_materials[i].fillna(df_materials[i].astype(float).mean())\n",
    "        df_curing[i] = df_curing[i].fillna(df_curing[i].astype(float).mean())\n",
    "\n",
    "        # Show optimal recipe only at the -> otherwise we would display it multiple times\n",
    "        # Original Recipe\n",
    "        # optimal_recipe = 360,0.5,\"0.5/0.5\",\"Heat curing\"\n",
    "        # Encoded original Recipe\n",
    "        optimal_recipe = [360 / max_powders, 0.5 / max_wc, 0.5 / max_materials, 0]\n",
    "\n",
    "        df_recipe_vectors['powders'] = df_powders[i].astype(float).values / max_powders - optimal_recipe[0]\n",
    "        df_recipe_vectors['wc'] = df_wc[i].astype(float).values / max_wc - optimal_recipe[1]\n",
    "        df_recipe_vectors['materials'] = df_materials[i].astype(float).values / max_materials - optimal_recipe[2]\n",
    "        df_recipe_vectors['curing'] = df_curing[i].astype(float).values / max_curing - - optimal_recipe[3]\n",
    "\n",
    "        for j in range(df_recipe_vectors.shape[0]):\n",
    "            distance_to_optimal = np.linalg.norm(df_recipe_vectors.loc[j,:].values)\n",
    "            if distance_to_optimal < 0.1:\n",
    "                print(df_recipe_vectors.loc[j,:].values)\n",
    "                print(distance_to_optimal)\n",
    "\n",
    "        # df_recipe_vectors = pd.DataFrame(df_recipe_vectors.T, columns=list(np.arange(15)))\n",
    "        df_recipe_vectors = df_recipe_vectors.dropna(axis=1)\n",
    "        # print(df_recipe_vectors.shape[0])\n",
    "        # print(df_recipe_vectors.shape[1])\n",
    "\n",
    "        tsne = TSNE(n_components=2, perplexity=8, random_state=42, n_iter=1000)\n",
    "        tsne_result = tsne.fit_transform(df_recipe_vectors)\n",
    "        unique_count = count_unique_tsne_points(tsne_result)\n",
    "        avg_dist = compute_avg_tsne_dist(tsne_result)\n",
    "\n",
    "        plt.scatter(tsne_result[:, 0], tsne_result[:, 1], label=f'Iteration {i} ({unique_count, avg_dist})')\n",
    "        plt.scatter(0, 0, marker='x', color='red', label='Optimal Recipe')\n",
    "        plt.xlabel('TSNE - x')\n",
    "        plt.ylabel('TSNE - y')\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        plt.title('TSNE along with unique recipes and their avg distance')\n",
    "        plt.show()\n",
    "    # plt.savefig(f'Results/Recipe_Distribution_Analysis/TSNE for Strategy {strategy} Temperature {temperature} Recursion {recursion}.png', bbox_inches='tight')\n",
    "\n",
    "    ####### Standard Deviations #######\n",
    "    std_for_each_run_powder = compute_std_over_different_runs(df_powders, number_of_iterations)\n",
    "    std_for_each_run_wc = compute_std_over_different_runs(df_wc, number_of_iterations)\n",
    "    std_for_each_run_materials = compute_std_over_different_runs(df_materials, number_of_iterations)\n",
    "    std_for_each_run_curing = compute_std_over_different_runs(df_curing, number_of_iterations)\n",
    "\n",
    "    # TODO:\n",
    "    recipe_vector_mean, std_for_recipe_vector = compute_overall_std(df_powders, df_wc, df_materials, df_curing, number_of_iterations)\n",
    "\n",
    "    full_std = std_for_each_run_powder + std_for_each_run_wc + std_for_each_run_materials + std_for_each_run_curing\n",
    "\n",
    "    if full:\n",
    "        std_for_statistics = full_std\n",
    "    else:\n",
    "        std_for_statistics = std_for_recipe_vector\n",
    "\n",
    "    # comment in to see details on the dfs\n",
    "    # print(df_powders)\n",
    "    # print(df_materials)\n",
    "    # print(df_wc)\n",
    "    # print(df_curing)\n",
    "\n",
    "    std_statistics.loc[len(std_statistics)] = {\n",
    "        'configuration': f'{strategy} {temperature} {recursion}',\n",
    "        'mean_std': np.mean(std_for_statistics),\n",
    "        'max_std': np.max(std_for_statistics),\n",
    "        'min_std': np.min(std_for_statistics),\n",
    "        'avg_std_gradient': _compute_avg_grad(std_for_statistics),\n",
    "        'initial_std': std_for_statistics[0],\n",
    "        'halftime_std': std_for_statistics[floor(number_of_iterations / 2)],\n",
    "        'final_std': std_for_statistics[number_of_iterations - 1],\n",
    "    }\n",
    "\n",
    "    nr_iterations = np.arange(0, number_of_iterations)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.plot(nr_iterations, std_for_each_run_powder, label='powderkg')\n",
    "    plt.plot(nr_iterations, std_for_each_run_wc, label='wc')\n",
    "    plt.plot(nr_iterations, std_for_each_run_materials, label='materials')\n",
    "    plt.plot(nr_iterations, std_for_each_run_curing, label='curing')\n",
    "\n",
    "\n",
    "    if full:\n",
    "        plt.plot(nr_iterations, full_std, label='Full Std')\n",
    "    else:\n",
    "        plt.plot(nr_iterations, recipe_vector_mean, label='Overall Mean')\n",
    "        plt.plot(nr_iterations, std_for_recipe_vector, label='Overall Std')\n",
    "        plt.fill_between(np.array(nr_iterations), np.array(recipe_vector_mean) - 0.25 * np.array(std_for_recipe_vector),\n",
    "                         np.array(recipe_vector_mean) + 0.25 * np.array(std_for_recipe_vector), color='yellow', alpha=0.3,\n",
    "                         label='Std')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.title(f'Std evolution for {strategy} {temperature} {recursion}')\n",
    "\n",
    "    plt.show()\n",
    "#     if full:\n",
    "#         plt.savefig(f'Results/Recipe_Distribution_Analysis/Full Std evolution for Strategy {strategy} Temperature {temperature} Recursion {recursion}.png', bbox_inches='tight')\n",
    "#     else:\n",
    "#         plt.savefig(f'Results/Recipe_Distribution_Analysis/Std evolution for Strategy {strategy} Temperature {temperature} Recursion {recursion}.png', bbox_inches='tight')\n",
    "#\n",
    "# if full:\n",
    "#     std_statistics.to_csv('Results/Recipe_Distribution_Analysis/Full std_statistics.csv')\n",
    "# else:\n",
    "#     std_statistics.to_csv('Results/Recipe_Distribution_Analysis/std_statistics.csv')\n",
    "\n",
    "print(f'####### Nr of warnings: {configs_with_less_than_ten_iterations} #######')\n",
    "\n",
    "# TODO: FIX\n",
    "# START\n",
    "#####################################################################################\n",
    "####### Run with strategy Specific, temperature 0.0 and recursion 0 #########"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}