{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "strategies = ['None', 'Specific', 'Generic']\n",
    "temperatures = ['0.0', '0.7']\n",
    "\n",
    "regex_patterns = {\n",
    "    'Powderkg': r'Powderkg = (\\d+)',\n",
    "    'wc': r'wc = ([\\d.]+)',\n",
    "    'materials': r'materials = ([\\d./]+)',\n",
    "    'curing': r'curing = (.+)$'\n",
    "}\n",
    "\n",
    "\n",
    "def find_explained_variance_using_pca(feature, strategy, temperature):\n",
    "    pca = PCA(n_components=1)\n",
    "    data = pd.DataFrame(correlation_matrix)\n",
    "    pca.fit(data)\n",
    "    # Get the first principal component\n",
    "    first_principal_component = pca.components_[0]\n",
    "    # Print the explained variance ratio, which tells you the proportion of variance\n",
    "    # explained by the first principal component.\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(f\"Explained Variance Ratio for {feature}, {strategy} and {temperature}:\", explained_variance_ratio)\n",
    "    # Print the first principal component, which represents the overall relationship\n",
    "    print(f\"First Principal Component (Overall Relationship) for {feature}, {strategy} and {temperature}:\", first_principal_component)\n",
    "\n",
    "\n",
    "def perform_correlation_analysis(feature, strategy, temperature):\n",
    "    correlation_matrix = df.corr()\n",
    "    correlation_matrix = correlation_matrix.apply(lambda x: round(x, 2))\n",
    "    average_cc_per_run = correlation_matrix.mean()\n",
    "    correlation_matrix['Average Correlation'] = average_cc_per_run\n",
    "    print('AVERAGE CORRELATION COEFFICIENT PER RUN')\n",
    "    print(average_cc_per_run)\n",
    "    overall_average_cc = correlation_matrix.stack().mean()\n",
    "    print('OVERALL CORRELATION COEFFICIENT')\n",
    "    print(overall_average_cc)\n",
    "    # NaNs occur when the std is 0, i.e. we have constant functions. We handle this cas by replacing NaN with 1\n",
    "    correlation_matrix.fillna(1, inplace=True)\n",
    "    correlation_matrix.to_csv(f'Results/Correlation_Analysis/correlation_matrix_{feature}_{strategy}_{temperature}.csv')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "    # Customize the plot (add labels, title, etc. if needed)\n",
    "    plt.title(f'Correlation Heatmap {strategy} {temperature}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_individual_experiments(feature, strategy, temperature):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(df.index, df[f'{feature} 1'], label=f'{feature} Experiment 1')\n",
    "    plt.plot(df.index, df[f'{feature} 2'], label=f'{feature} Experiment 2')\n",
    "    plt.plot(df.index, df[f'{feature} 3'], label=f'{feature} Experiment 3')\n",
    "    plt.legend()\n",
    "    plt.title(f'Lineplot for {strategy} and {temperature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_data_for_given_run(pattern):\n",
    "    matching_filenames = []\n",
    "    # Iterate through the files in the directory\n",
    "    dir_name = 'Results/ID'\n",
    "    for filename in os.listdir(dir_name):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            matching_filenames.append(os.path.join(dir_name, filename))\n",
    "    all_results_df = pd.DataFrame()\n",
    "    warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)\n",
    "    for i, filename in enumerate(matching_filenames):\n",
    "        results_sample_df = pd.read_csv(filename)\n",
    "        results_sample_df.head(2)\n",
    "        for col, pattern in regex_patterns.items():\n",
    "            all_results_df[f'{col} {i}'] = results_sample_df['Formulation'].str.extract(pattern, expand=False)\n",
    "            if col.startswith('materials'):\n",
    "                all_results_df[f'{col} {i}'] = all_results_df[f'{col} {i}'].str[:3].astype(float)\n",
    "            if col.startswith('curing'):\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Heat')] = 0\n",
    "                all_results_df[f'{col} {i}'][all_results_df[f'{col} {i}'].astype(str).str.startswith('Ambient')] = 1\n",
    "    return all_results_df, matching_filenames\n",
    "\n",
    "\n",
    "def tsne_for_feature(feature, strategy, temperature):\n",
    "    X_2d = tsne.fit_transform(df_transpose)\n",
    "    # Create a scatter plot of the t-SNE results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c='r', marker='o', label=feature)\n",
    "    plt.title(f\"t-SNE Visualization {strategy} {temperature}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def tsne_for_all_features(all_features_for_tsne, strategy, temperature):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_features_for_tsne)\n",
    "    # Transform your DataFrame to apply the scaling\n",
    "    scaled = pd.DataFrame(scaler.transform(all_features_for_tsne))\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=0)\n",
    "    X_2d = tsne.fit_transform(scaled)\n",
    "    # Create a scatter plot of the t-SNE results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c='r', marker='o', label='All Features')\n",
    "    plt.title(f\"t-SNE Visualization all features {strategy} {temperature}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pca_and_corr_on_all_features():\n",
    "    correlation_matrix = df.corr()\n",
    "    correlation_matrix = correlation_matrix.apply(lambda x: round(x, 8))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "    # Customize the plot (add labels, title, etc. if needed)\n",
    "    plt.title('Correlation Heatmap between Lineplots')\n",
    "    plt.show()\n",
    "    pca = PCA(n_components=1)\n",
    "    data = pd.DataFrame(correlation_matrix)\n",
    "    pca.fit(data)\n",
    "    # Get the first principal component\n",
    "    first_principal_component = pca.components_[0]\n",
    "    # Print the explained variance ratio, which tells you the proportion of variance\n",
    "    # explained by the first principal component.\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    print(\"Explained Variance Ratio:\", explained_variance_ratio)\n",
    "    # Print the first principal component, which represents the overall relationship\n",
    "    print(\"First Principal Component (Overall Relationship):\", first_principal_component)\n",
    "\n",
    "\n",
    "for strategy in strategies:\n",
    "    for temperature in temperatures:\n",
    "        # TODO: What about Specific and 0.7?\n",
    "        if strategy == 'Specific' and temperature == '0.7':\n",
    "            continue\n",
    "        print('#####################################################################################')\n",
    "        print(f'################ RUN with strategy: {strategy} and temperature {temperature} ####################')\n",
    "        print('#####################################################################################')\n",
    "\n",
    "        pattern = fr'gpt-3.5-turbo_{strategy}_prompt_experiment_(\\d+)_temp_{temperature}_target_(\\d+)_\\%_Dev_Budget_(\\d+)_recursive_1_(\\d+)\\.csv'\n",
    "        all_results_df, matching_filenames = extract_data_for_given_run(pattern)\n",
    "\n",
    "        warnings.filterwarnings(\"default\")\n",
    "\n",
    "        features = ['Powderkg', 'wc', 'materials']\n",
    "        for feature in features:\n",
    "            print(f'################ Feature {feature} ################')\n",
    "            data = {}\n",
    "            for i in range(len(matching_filenames)):\n",
    "                data[f'{feature} {i}'] = list(all_results_df[f'{feature} {i}'].values)\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            perform_correlation_analysis(feature, strategy, temperature)\n",
    "            # plot_individual_experiments(feature, strategy, temperature)\n",
    "            find_explained_variance_using_pca(feature, strategy, temperature)\n",
    "\n",
    "            tsne = TSNE(n_components=2, perplexity=5, random_state=0)\n",
    "            df_transpose = df.T\n",
    "            if feature == 'Powderkg':\n",
    "                all_features_for_tsne = df_transpose.values\n",
    "            else:\n",
    "                all_features_for_tsne = np.hstack((all_features_for_tsne, df_transpose.values))\n",
    "            tsne_for_feature(feature, strategy, temperature)\n",
    "\n",
    "        tsne_for_all_features(all_features_for_tsne, strategy, temperature)\n",
    "\n",
    "        df = pd.DataFrame(all_features_for_tsne).T\n",
    "        df.head(30)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df)\n",
    "\n",
    "        # Transform your DataFrame to apply the scaling\n",
    "        scaled_df = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "\n",
    "        plt.plot(scaled_df.index, scaled_df[1].astype(str))\n",
    "        plt.plot(scaled_df.index, scaled_df[2].astype(str))\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "\n",
    "        # pca_and_corr_on_all_features()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}